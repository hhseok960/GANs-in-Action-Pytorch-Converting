{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed49718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shdhk\\anaconda3\\envs\\agent\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\shdhk\\anaconda3\\envs\\agent\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e00a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "CHANNELS, IMG_ROWS, IMG_COLS = 1, 28, 28\n",
    "IMG_SHAPE = (CHANNELS, IMG_ROWS, IMG_COLS)\n",
    "Z_DIM = 100\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51c79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, num_labeled):\n",
    "        self.num_labeled = num_labeled\n",
    "        download_root = \"./MNIST_DATASET\"\n",
    "        train_dataset = MNIST(download_root, train=True, download=True)\n",
    "        test_dataset = MNIST(download_root, train=False, download=True)\n",
    "        self.x_train, self.y_train = train_dataset.data.to(DEVICE), train_dataset.targets.to(DEVICE)\n",
    "        self.x_test, self.y_test = test_dataset.data.to(DEVICE), test_dataset.targets.to(DEVICE)\n",
    "\n",
    "        self.x_train, self.x_test = self.x_train / 127.5 - 1.0, self.x_test / 127.5 - 1.0\n",
    "        self.x_train, self.x_test = torch.unsqueeze(self.x_train, 1), torch.unsqueeze(self.x_test, 1)\n",
    "\n",
    "    def batch_labeled(self, batch_size):\n",
    "        idx = np.random.randint(low=0, high=self.num_labeled, size=batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        labels = self.y_train[idx]\n",
    "        return imgs, labels\n",
    "\n",
    "    def batch_unlabeled(self, batch_size):\n",
    "        idx = np.random.randint(low=self.num_labeled, high=self.x_train.shape[0], size=batch_size)\n",
    "        imgs = self.x_train[idx]\n",
    "        return imgs\n",
    "\n",
    "    def training_set(self):\n",
    "        x_train = self.x_train[range(self.num_labeled)]\n",
    "        y_train = self.y_train[range(self.num_labeled)]\n",
    "        return x_train, y_train\n",
    "\n",
    "    def test_set(self):\n",
    "        return self.x_test, self.y_test\n",
    "\n",
    "\n",
    "NUM_LABELED = 1000\n",
    "dataset = Dataset(num_labeled=NUM_LABELED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8805ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 12544]       1,266,944\n",
      "   ConvTranspose2d-2          [-1, 128, 14, 14]         295,040\n",
      "       BatchNorm2d-3          [-1, 128, 14, 14]             256\n",
      "         LeakyReLU-4          [-1, 128, 14, 14]               0\n",
      "   ConvTranspose2d-5           [-1, 64, 14, 14]          73,792\n",
      "       BatchNorm2d-6           [-1, 64, 14, 14]             128\n",
      "         LeakyReLU-7           [-1, 64, 14, 14]               0\n",
      "   ConvTranspose2d-8            [-1, 1, 28, 28]             577\n",
      "              Tanh-9            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 1,636,737\n",
      "Trainable params: 1,636,737\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.97\n",
      "Params size (MB): 6.24\n",
      "Estimated Total Size (MB): 7.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Linear(z_dim, 256 * 7 * 7)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(-1, 256, 7, 7)\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "generator = Generator(z_dim=Z_DIM).to(DEVICE)\n",
    "summary(generator, (Z_DIM,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef204eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 14, 14]             320\n",
      "         LeakyReLU-2           [-1, 32, 14, 14]               0\n",
      "            Conv2d-3             [-1, 64, 7, 7]          18,496\n",
      "         LeakyReLU-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5            [-1, 128, 3, 3]          73,856\n",
      "         LeakyReLU-6            [-1, 128, 3, 3]               0\n",
      "           Dropout-7            [-1, 128, 3, 3]               0\n",
      "           Flatten-8                 [-1, 1152]               0\n",
      "            Linear-9                   [-1, 10]          11,530\n",
      "================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.18\n",
      "Params size (MB): 0.40\n",
      "Estimated Total Size (MB): 0.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=img_shape[0], out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=0),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 3 * 128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "discriminator_semi = Discriminator(img_shape=IMG_SHAPE).to(DEVICE)\n",
    "summary(discriminator_semi, IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91479ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_d_sl = optim.Adam(discriminator_semi.parameters(), lr=0.0002)\n",
    "optimizer_d_ul = optim.Adam(discriminator_semi.parameters(), lr=0.0002)\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "criterion4sl = nn.CrossEntropyLoss()\n",
    "criterion4ul = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abce4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 [D(SL) loss: 0.0794] [D(UL) loss: 0.0014] [G loss: 56.2097]\n",
      "1600 [D(SL) loss: 0.0217] [D(UL) loss: 0.0000] [G loss: 90.6599]\n",
      "2400 [D(SL) loss: 0.0190] [D(UL) loss: 0.0000] [G loss: 94.5943]\n",
      "3200 [D(SL) loss: 0.0049] [D(UL) loss: 0.0000] [G loss: 99.3379]\n",
      "4000 [D(SL) loss: 0.0031] [D(UL) loss: 0.0000] [G loss: 100.0000]\n",
      "4800 [D(SL) loss: 0.0003] [D(UL) loss: 0.0000] [G loss: 100.0000]\n",
      "5600 [D(SL) loss: 0.0047] [D(UL) loss: 0.0000] [G loss: 100.0000]\n",
      "6400 [D(SL) loss: 0.0034] [D(UL) loss: 0.0000] [G loss: 100.0000]\n",
      "7200 [D(SL) loss: 0.0155] [D(UL) loss: 0.0000] [G loss: 100.0000]\n",
      "8000 [D(SL) loss: 0.0002] [D(UL) loss: 0.0000] [G loss: 99.2524]\n"
     ]
    }
   ],
   "source": [
    "supervised_losses, iteration_checkpoints = [], []\n",
    "iterations = 8000\n",
    "batch_size = 128\n",
    "sample_interval = 800\n",
    "\n",
    "real = torch.ones(batch_size, 1).to(DEVICE)\n",
    "fake = torch.zeros(batch_size, 1).to(DEVICE)\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    imgs, labels = dataset.batch_labeled(batch_size)\n",
    "    imgs_unlabeled = dataset.batch_unlabeled(batch_size)\n",
    "\n",
    "    z = torch.randn(batch_size, Z_DIM).to(DEVICE)\n",
    "    gen_imgs = generator(z).detach()\n",
    "    \n",
    "    optimizer_d_sl.zero_grad()\n",
    "    d_pred_sl = discriminator_semi(imgs)\n",
    "    d_loss_sl = criterion4sl(d_pred_sl, labels)\n",
    "    d_loss_sl.backward()\n",
    "    optimizer_d_sl.step()\n",
    "\n",
    "    optimizer_d_ul.zero_grad()\n",
    "    d_pred_real, d_pred_fake = discriminator_semi(imgs_unlabeled), discriminator_semi(gen_imgs)\n",
    "    d_pred_real = 1.0 - (1.0 / (torch.sum(torch.exp(d_pred_real), dim=-1, keepdim=True) + 1.0))\n",
    "    d_pred_fake = 1.0 - (1.0 / (torch.sum(torch.exp(d_pred_fake), dim=-1, keepdim=True) + 1.0))\n",
    "    \n",
    "    # d_pred_real, d_pred_fake = d_pred_real.detach(), d_pred_fake.detach()\n",
    "    \n",
    "    d_loss_real, d_loss_fake = criterion4ul(d_pred_real, real), criterion4ul(d_pred_fake, fake)\n",
    "    d_loss_ul = (d_loss_real + d_loss_fake) * 0.5\n",
    "    d_loss_ul.backward()\n",
    "    optimizer_d_ul.step()\n",
    "\n",
    "    z = torch.randn(batch_size, Z_DIM).to(DEVICE)\n",
    "    gen_imgs = generator(z).detach()\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    d_pred_fake = discriminator_semi(gen_imgs)\n",
    "    d_pred_fake = 1.0 - (1.0 / (torch.sum(torch.exp(d_pred_fake), dim=-1, keepdim=True) + 1.0))\n",
    "    g_loss = criterion4ul(d_pred_fake, real)\n",
    "    g_loss.backward()\n",
    "    optimizer_g.step()\n",
    "\n",
    "    if (iteration + 1) % sample_interval == 0:\n",
    "        supervised_losses.append(d_loss_sl.item())\n",
    "        iteration_checkpoints.append(iteration + 1)\n",
    "        print(f\"{iteration + 1} [D(SL) loss: {d_loss_sl.item():.4f}] \"\n",
    "              f\"[D(UL) loss: {d_loss_ul.item():.4f}] [G loss: {g_loss.item():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a37301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9386000037193298\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X, y = dataset.test_set()\n",
    "    discriminator_semi.eval()\n",
    "    prediction = discriminator_semi(X)\n",
    "    correct = torch.argmax(prediction, 1) == y\n",
    "    accuracy = correct.float().mean()\n",
    "    print(accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
